{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Algorithms for Data Science**\n\n## **Homework # 3**\n \n## **Ricardo Alvarez - ralvar16**","metadata":{}},{"cell_type":"code","source":"# code cell to input all the functions and libraries necessary\nimport pandas as pd # importing the panda library \n\n# name of the input file\nirisInput = \"../input/a4dshw3data/iris.csv\"\nfeaturesInput = \"../input/a4dshw3data/trainFeatures.csv\"\nfeaturesInput2 = \"../input/a4dshw3data/trainFeatures.xls\"","metadata":{"execution":{"iopub.status.busy":"2022-03-23T12:03:18.2965Z","iopub.execute_input":"2022-03-23T12:03:18.297425Z","iopub.status.idle":"2022-03-23T12:03:18.325146Z","shell.execute_reply.started":"2022-03-23T12:03:18.297298Z","shell.execute_reply":"2022-03-23T12:03:18.32417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***\n# **1. Problem 1 - Module 4 and 5**\n\n10 points total\n\nIn this problem use the developed numerical features from HW2. In this problem the following is to be completed:\n\n***","metadata":{}},{"cell_type":"markdown","source":"##  (a) (5 points)  For each combination of number apply the FDR, e.g., 0 vs 1, 0 vs 2, ..., 0 vs 9, ..., 8 vs 6, 8 vs 7, 8 vs 9.","metadata":{}},{"cell_type":"code","source":"# The features data set from excel is stored in a Panda structure\nfeaturesPanda = pd.read_csv(featuresInput)\n#featuresPanda2 = pd.read_excel(featuresInput2, sheet_name = \"Sheet 1\")\nfeaturesPanda","metadata":{"execution":{"iopub.status.busy":"2022-03-23T12:04:42.177712Z","iopub.execute_input":"2022-03-23T12:04:42.178215Z","iopub.status.idle":"2022-03-23T12:04:42.214993Z","shell.execute_reply.started":"2022-03-23T12:04:42.178173Z","shell.execute_reply":"2022-03-23T12:04:42.214099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This code cell is intended to initialize all the variables that will be used in this Problem\n\n\n\n\nimport pandas as pd # importing the panda library \nimport seaborn as sns # importing the seaborn library for statistical visualization\nfrom scipy.fft import dct # importing scipy\nfrom scipy import stats, fft\nimport numpy as np # importing numpy as np\nimport matplotlib.pyplot as plt # importing MatPlotLib for visualization plotting \nfrom sklearn.decomposition import PCA #importing PCA from Scikit Learn Package\nimport csv\n\n\n\n# name of the input file\nirisInput = \"../input/a4dshw3data/iris.csv\"\ntrainInput = \"train.csv\"\n\n#Trimmed mean percentage\ntrimMean = 0.25","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***\n**(a) (5 points) Develop an algorithm to read in the iris.csv file.**\n\n*To develop this part the input file  will be open to be read in a general manner.*\n***","metadata":{}},{"cell_type":"code","source":"# This algorithm will read the iris.csv file with the data in a generic form\nfileName = open(irisInput,\"r\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***\n**(b) (5 points) Develop an algorithm to store the data in a data structure of your choice, e.g., array, matrix, etc.**\n\n*To develop this part the input will be open to be read in a Panda structure directly.*\n***","metadata":{}},{"cell_type":"code","source":"# After reading the iris.csv file in a generic for,m, the data obtained from the input file is stored in a Panda structure\nIrisPanda = pd.read_csv(irisInput)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***\n**(c) (10 points) Perform statistics of each feature and class using the test statistics listed in Table 1**\n\n*For this part, the code will compute the following: minimum, maximum, mean, trimmed mean, standard deviation, skewness and kurtosis.*\n***","metadata":{}},{"cell_type":"code","source":"# A Panda structure with the general statistics is created\nStatsPanda = pd.DataFrame([]) # the panda with the statistics is initialized as an empty panda structure\nSpeciesPanda = pd.DataFrame([]) # the panda with the class data\nStatsClassPanda  = pd.DataFrame([])  # the panda with single statistics is initialized\n\n# required statistics to perform the analysis\nstatistics = [\"minimum\", \"maximum\", \"mean\", \"trimmed mean\", \"standard deviation\",\"skewness\",\"kurtosis\"]\n\n# species\nSpeciesPanda = IrisPanda[\"species\"].drop_duplicates()\nspecies = SpeciesPanda.to_numpy()\n\n# loop to create the Panda structure to list all the statistics to be obtained\nirisFeatures = list(IrisPanda.columns)\n\n# the species column is eliminated \nirisFeatures.remove(\"species\")\n\n# data structure for each species\nSetosaStructure = IrisPanda[0:50].drop(\"species\",axis=1)\nVersicolorStructure = IrisPanda[50:100].drop(\"species\",axis=1)\nVirginicaStructure = IrisPanda[100:150].drop(\"species\",axis=1)#\n\n#List with Panda structure for each species\nClassStructure =[SetosaStructure, VersicolorStructure, VirginicaStructure]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Computing the statistics for each feature in the data frame\nfor feature in irisFeatures:\n    #minimum values\n    StatsPanda.at[\"minimum\",feature] = IrisPanda[feature].min()\n    #maximum values\n    StatsPanda.at[\"maximum\",feature] = IrisPanda[feature].max()\n    #mean values\n    StatsPanda.at[\"mean\",feature] = IrisPanda[feature].mean()\n    #standard deviation values\n    StatsPanda.at[\"standard deviation\",feature] = IrisPanda[feature].std()\n    #skewness\n    StatsPanda.at[\"skewness\",feature] = IrisPanda[feature].skew()\n    #kurtosis\n    StatsPanda.at[\"kurtosis\",feature] = \\\n        stats.kurtosis(IrisPanda[feature],fisher = True, bias = False) \n    # trimmed mean\n    StatsPanda.at[f\"trimmed mean @ {trimMean * 100}%\",feature] \\\n        = stats.trim_mean(IrisPanda.loc[:,feature],trimMean)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Statistics by class**","metadata":{}},{"cell_type":"code","source":"#Computing the statistics for each class of flower\ntypeindex = 0\n\nfor flowerType in species:\n    for feature in irisFeatures:\n        #minimum values\n        StatsClassPanda.at[f\"minimum \" + flowerType,feature] = ClassStructure[typeindex][feature].min()\n        #maximum values\n        StatsClassPanda.at[f\"maximum \" + flowerType,feature] = ClassStructure[typeindex][feature].max()\n        #mean values\n        StatsClassPanda.at[f\"mean \" + flowerType,feature] = ClassStructure[typeindex][feature].mean()\n        #standard deviation values\n        StatsClassPanda.at[f\"standard deviation \" + flowerType,feature] = ClassStructure[typeindex][feature].std()\n        #skewness\n        StatsClassPanda.at[f\"skewness \" + flowerType,feature] = ClassStructure[typeindex][feature].skew()\n        #kurtosis\n        StatsClassPanda.at[f\"kurtosis \" + flowerType,feature] = \\\n            stats.kurtosis(ClassStructure[typeindex][feature])\n            #, fisher = True, bias = False)\n        # trimmed mean\n        StatsClassPanda.at[f\"trimmed mean @ {trimMean * 100}% \" + flowerType,feature] = \\\n            stats.trim_mean(ClassStructure[typeindex].loc[:,feature],trimMean)\n    typeindex = typeindex + 1\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Code to graph the data of the datasets in a comparison view\ncolors = [\"blue\", \"red\", \"green\"]\n\n#Sepal Length graph\ndef sepalLengthGraph():\n    for i in range(len(ClassStructure)):\n        xVal = ClassStructure[i][\"sepal_length\"]\n        yVal = np.zeros_like(xVal) # generic y axis data\n        plt.plot(xVal, yVal+ i,\".\",color = colors[i],label = species[i])\n        plt.yticks([])\n        plt.legend(loc=\"upper left\")\n        plt.title(\"Sepal Length\")\n\n#Sepal Width graph\ndef sepalWidthGraph():\n    for i in range(len(ClassStructure)):\n        xVal = ClassStructure[i][\"sepal_width\"]\n        yVal = np.zeros_like(xVal) # generic y axis data\n        plt.plot(xVal, yVal+ i,\".\",color = colors[i],label = species[i])\n        plt.yticks([])\n        plt.legend(loc=\"center right\")\n        plt.title(\"Sepal Width\")\n\n#Petal Length graph\ndef petalLengthGraph():\n    for i in range(len(ClassStructure)):\n        xVal = ClassStructure[i][\"petal_length\"]\n        yVal = np.zeros_like(xVal) # generic y axis data\n        plt.plot(xVal, yVal+ i,\".\",color = colors[i],label = species[i])\n        plt.yticks([])\n        plt.legend(loc=\"center right\")\n        plt.title(\"Petal Length\")\n\n#Petal Length graph\ndef petalWidthGraph():\n    for i in range(len(ClassStructure)):\n        xVal = ClassStructure[i][\"petal_width\"]\n        yVal = np.zeros_like(xVal) # generic y axis data\n        plt.plot(xVal, yVal+ i,\".\",color = colors[i],label = species[i])\n        plt.yticks([])\n        plt.legend(loc=\"center right\")\n        plt.title(\"Petal Width\")\n\ndef classGraph():\n    #sns.set(rc={'figure.figsize':(15,15)})\n    rel = sns.pairplot(IrisPanda, hue='species', palette=\"husl\")\n    rel.fig.suptitle('PairPlot Analysis')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***\n**(d) (10 points) Perform analysis and provide an explanation of what each of the statistics provides of the data.**\n\n*For this part, the code will compute the following: minimum, maximum, mean, trimmed mean, standard deviation, skewness and kurtosis.*\n***","metadata":{}},{"cell_type":"markdown","source":"# General analysis of the data set as a whole\nFirst an analysis of the total statistics over the whole dataset is performed:","metadata":{}},{"cell_type":"code","source":"StatsPanda #Statistiscs charts from the whole dataset","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Sepal length","metadata":{}},{"cell_type":"markdown","source":"The data shows that between all the species the sepal length varies from a minimum value of 4.3 to a maximum value of 7.9 with a mean or average value of 5.84 approximately. The standard deviation is 0.82, approximately 14% of the average, which gives us a measurement of how disperse are the values of the data with respect to the average. In comparison with the other features the dispersion evaluating the standard deviation of the sepal length is similar to dispersion of the sepal width, and very low compared to the standard deviation obtained for the petal values. \n\nFor the trimmed mean I tried first with 10% as the portion to cut (slices of \"leftmost\" and \"rightmost\" of 10% of the values) and the value obtained for the trimmed mean was approximately 5.81. Afterwards, I changed the value to 25%, and the obtained trimmed mean is 5.80. This means that the obtained value of normal average or mean, that is 5.84, is very accurate and the data set does not present too many outliers.\n\nFor the sepal length, the skewness has a positive value of 0.31, therefore the mean value is expected to be higher than the median value and the mode, therefore more values are expected to be less than the average. So the majority of the of the sepal lengths tend to be lower than the mean. For the sepal length, the skewness has a positive value of 0.31, therefore the mean value is expected to be higher than the median value and the mode, therefore more values are expected to be less than the average. So the majority of the of the sepal lengths tend to be lower than the mean. And the kurtosis has a negative value of -0.55 which tells us that the distribution of the values is slightly more dispersed than a normal distribution, this means that the value are a little farther from the mean than was is expected in a normal distribution.","metadata":{}},{"cell_type":"code","source":"sepalLengthGraph()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the plot above, it can be seen that the Setosa species tends to have a bigger sepal length than Versicolor and Virginica. From the three, Setosa seems to have a less dispersed distribution of values for the sepal length than the other 2 species. ","metadata":{}},{"cell_type":"markdown","source":"# Sepal width\nThe data shows that between all the species the sepal width varies from a minimum value of 2.0 to a maximum value of 4.4 with a mean or average value of 3.05 approximately. The standard deviation is 0.43, approximately 14% of the average, which gives us a measurement of how disperse are the values of the data with respect to the average. In comparison with the other features the dispersion evaluating the standard deviation of the sepal width is similar to dispersion of the sepal length, and very low compared to the standard deviation obtained for the petal values. \n\nFor the trimmed mean I tried first with 10% as the portion to cut (slices of \"leftmost\" and \"rightmost\" of 10% of the values) and the value obtained for the trimmed mean was approximately 3.04. Afterwards, I changed the value to 25%, and the obtained trimmed mean is 3.03. This means that the obtained value of normal average or mean, that is 3.04, is very accurate and the data set does not present too many outliers.\n\nFor the sepal width, the skewness has a positive value of 0.33, therefore similarly to the sepal length the mean value is expected to be higher than the median value and the mode, therefore more values are expected to be less than the average. So the majority of the of the sepal widths tend to be lower than the mean. And the kurtosis has a positive value of 0.29 which tells us that the distribution of the values is slightly less dispersed than a normal distribution, this means that the value tend to be a little more closer to the mean than was is expected in a normal distribution.","metadata":{}},{"cell_type":"code","source":"sepalWidthGraph()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the plot above, it can be seen that all 3 species tends to have similar value for the sepal width, with some tendency of the Setosa specie to have bigger sepal width. Interestingly, Setosa and Virginica seems to have some outliers values that were indeed corrected with the trimmed mean.","metadata":{}},{"cell_type":"markdown","source":"# Petal length\nThe data shows that between all the species the petal length varies from a minimum value of 1.0 to a maximum value of 6.9 with a mean or average value of 3.76 approximately. The standard deviation is 1.76, approximately 47% of the average, which gives us a measurement of how disperse are the values of the data with respect to the average. In comparison with the other features the dispersion evaluating the standard deviation of the petal length is higher to the dispersion of the sepal measurements of width and length, however is a little bit lower than the standard deviation obtained for the petal width. \n\nFor the trimmed mean I tried first with 10% as the portion to cut (slices of \"leftmost\" and \"rightmost\" of 10% of the values) and the value obtained for the trimmed mean was approximately 3.76. Afterwards, I changed the value to 25%, and the obtained trimmed mean is 3.93. This means that the trimmed value did eliminate some outliers and increased the average by 4%.\n\nFor the petal length, the skewness has a negative value of -0.27, therefore the mean value is expected to be lower than the median value and the mode, therefore more values are expected to be greater than the average. So the majority of the petal lengths tend to be greater than the mean. And the kurtosis has a negative value of -1.40 which tells us that the distribution of the values is more dispersed than a normal distribution, this means that the values tend to be farther to the mean than was is expected in a normal distribution.","metadata":{}},{"cell_type":"code","source":"petalLengthGraph()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the plot above, it can be seen there is a pronounced tendency in the difference of sizes for the petal length. The Setosa species clearly has a smaller size of petal length and the Virginica specie has a bigger size of petal length. The Versicolor specie is in the middle, but with a tendency to get closer to the petal lengths of the Virginica specie.","metadata":{}},{"cell_type":"markdown","source":"# Petal width\nThe data shows that between all the species the petal width varies from a minimum value of 0.1 to a maximum value of 2.5 with a mean or average value of 1.2 approximately. The standard deviation is 0.76, approximately 63% of the average, which gives us a measurement of how disperse are the values of the data with respect to the average. In comparison with the other features the dispersion evaluating the standard deviation of the petal width is the highest of all measurements of width and length. Therefore a very disperse measurements of the petal width is expected.\n\nFor the trimmed mean I tried first with 10% as the portion to cut (slices of \"leftmost\" and \"rightmost\" of 10% of the values) and the value obtained for the trimmed mean was approximately 1.18. Afterwards, I changed the value to 25%, and the obtained trimmed mean is 1.23. This means that the trimmed value at 10% was not very accurate, and modifying it to 25% helped a little bit to reduce the outliers.\n\nFor the petal widths, the skewness has a negative value of -0.10, therefore the mean value is expected to be slightly lower than the median value and the mode, therefore more values are expected to be greater than the average. However, the skewness is closer to 0 than in the petal length so only a small majority of the petal widths tend to be greater than the mean. And, similar to the petal length, the kurtosis has a negative value of -1.33 which tells us that the distribution of the values is more dispersed than a normal distribution, this means that the values tend to be farther to the mean than was is expected in a normal distribution.\n","metadata":{}},{"cell_type":"code","source":"petalWidthGraph()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the plot above, it can be seen there is a pronounced tendency in the difference of sizes for the petal width. The Setosa species clearly has a smaller size of petal width and the Virginica specie has a bigger size of petal width. The Versicolor specie is in the middle, but with a tendency to get closer to the petal width of the Virginica specie.","metadata":{}},{"cell_type":"markdown","source":"# Analysis of the data by species.\nFirst an analysis of the statistics by each individual specie is performed and the table of the statistics is shown below:","metadata":{}},{"cell_type":"code","source":"StatsClassPanda #table with the separate statistics by class","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The statistics for the different species is addressed above.\n\n# Sepal length\nThe species with the minimum sepal length is the Setosa (4.3) and the one with the maximum is Virginca (7.9). Also the means from the three species have the same relationship accordingly. The standard deviation is lower in Setosa (0.35) and higher in Virginica (0.64) as already discussed in the analysis above. For all the species the trimmed mean gives a value that is almost equal to the mean, therefore the outliers were removed and no significant variation from the trimmed mean and the mean is present, so the contribution of the outliers is not significant for any species. The skewness is positive in every species also, therefore the mean values of the sepal length for all species tend to be lower than the mean, similar to the result obtained for the general sepal length discussed above. The same happens with the kurtosis, that every species has an individual negative value of kurtosis, obtaining the same tendency as the general sepal length.\n\n# Sepal width\nThe species with the minimum sepal width is the Versicolor (2.0) and the one with the maximum is Setosa (4.4). Also the means from the three species have the same relationship accordingly. The standard deviation is lower in Versicolor (0.31) and higher in Setosa (0.38) as already discussed in the analysis above. For all the species the trimmed mean gives a value that is almost equal to the mean, therefore the outliers were removed and no significant variation from the trimmed mean and the mean is present, so the contribution of the outliers is not significant for any species. The skewness is positive for setosa (0.11) and virginica (0.37) and negative for versicolor (-0.36), therefore the versicolor species does not follows the trends from the overalls measurements of sepal widths as discussed above. The same happens with the kurtosis, and only the versicolor has a negative kurtosis (-0.44).\n\n# Petal length\nThe species with the minimum petal length is the Setosa (1.0) and the one with the maximum is Virginca (6.9). Also the means from the three species have the same relationship accordingly. The standard deviation is lower in Setosa (0.17) and higher in Virginica (0.55) as already discussed in the analysis above. For all the species the trimmed mean gives a value that is almost equal to the mean, therefore the outliers were removed and no significant variation from the trimmed mean and the mean is present, so the contribution of the outliers is not significant for any species. The skewness is positive for setosa (0.07) and virginica (0.55) and negative for versicolor (-0.60), but interstingly the versicolor has such a higher negative value that makes the skewness of the general petal length to be also negative even when the other two species have positives skewness. The kurtosis is positive for setosa (0.81) and negative for versicolor (-0.07) and virginica (-0.25), therefore the setosa species does not follows the trends from the overalls measurements of petal lengths as discussed above.\n\n# Petal width\nThe species with the minimum petal width is the Setosa (0.1) and the one with the maximum is Virginca (2.5). Also the means from the three species have the same relationship accordingly. The standard deviation is lower in Setosa (0.11) and higher in Virginica (0.27) as already discussed in the analysis above. For versicolor and virginica the trimmed mean gives a value that is almost equal to the mean, therefore the outliers were removed and no significant variation from the trimmed mean and the mean is present, so the contribution of the outliers is not significant for any species. However, for setosa the trimmed mean and the mean has a difference of more than 10%, therefore the contribution of the outliers in the statistics can be significant and should be taken into account. The skewness is positive for setosa (0.07) and negative for versicolor (-0.03) and virginica (-0.13), therefore the setosa species does not follows the trends from the overalls measurements of petal widths as discussed above. The kurtosis is positive for setosa (0.81) and negative for versicolor (-0.49) and virginica (-0.66), therefore the setosa species does not follows the trends from the overalls measurements of petal lengths as discussed above.","metadata":{}},{"cell_type":"code","source":"classGraph() #Graph of the entire data using the seaborn library","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The graph above gives a relationship between different features. For example:\n1) Those flowers with larger magnitude of petal widths, tends to have larger magnitudes of all the other features (petal length, sepal width and sepal length). This is observed in the top three graphs of the forth column. In the majority of cases the larger magnitude is in the Virginica.\n2) The petal length and width is always smaller in the setosa species. This is observed in the graphs of the third column and forth column, and is also discussed above. Therefore the smallest petals are always from the setosa species.\n3) The petal length and width are almost always greater in the virginica species. This is observed in the graphs of the third column and forth column, and is also discussed above. Therefore the biggest petals are always from the setosa species.\n\nThis graphs helps us to be able to visualize information from the table in a graphical manner.","metadata":{}},{"cell_type":"markdown","source":"***\n# **2. Problem 2**\n***","metadata":{}},{"cell_type":"markdown","source":"***\n**(a) (5 points) Develop an algorithm to read in the train.csv file.**\n\n*To develop this part the input file  will be open to be read in a general manner.*\n***","metadata":{}},{"cell_type":"code","source":"# This algorithm will read the iris.csv file with the data in a generic form\ninputFile = open(trainInput,\"r\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***\n**(b) (5 points) Develop an algorithm to store the data in a data structure of your choice so that the data is reshaped into a matrix of size 28 × 28.**\n\n*To develop this part the input will be open to be read in a Panda structure directly.*\n***","metadata":{}},{"cell_type":"code","source":"# After reading the iris.csv file in a generic for,m, the data obtained from the input file is stored in a Panda structure\nTrainPanda = pd.read_csv(trainInput)\n\n#A new panda is created dropping the first label column to prepare for reshape\nPixelPanda = TrainPanda.drop(\"label\",axis=1)\n\n#The array is reshaped to 28 x 28 matrices for the 42,000 images on the file\nReshapedPanda = PixelPanda.values.reshape(42000,28,28)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***\n**(c) (5 points) Plot the developed matrix for indices 1, 2, 4, 7, 8, 9, 11, 12, 17, and 22. These indices represent the numerical values from 0 to 9.**\n***","metadata":{}},{"cell_type":"code","source":"#indices to be used\nIndex = [1, 2, 4, 7, 8, 9, 11, 12, 17, 22]\n\nfor i in range(len(Index)):\n    plt.subplot(2, 5, i+1)\n    data = ReshapedPanda[Index[i]-1]\n    plt.imshow(data, 'gray')\n    plt.title(f\"Index= {Index[i]}\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***\n\n# **3. Problem 3**\n\n***","metadata":{}},{"cell_type":"markdown","source":"***\n**(a) (10 points) Take the 2 dimensional Discrete Cosine Transform (DCT) of each matrix from Problem 2, the matrix represents each number.**\n***","metadata":{}},{"cell_type":"markdown","source":"To demonstrate the functionality, the DCT transforms are plotted for the 10 index of Problem 2 given in the PDF, this are Index = [1, 2, 4, 7, 8, 9, 11, 12, 17, 22]","metadata":{}},{"cell_type":"code","source":"#indices to be used\nIndex2 = [1, 2, 4, 7, 8, 9, 11, 12, 17, 22]\nplotControl = 0\nIndex = range(1000)\n\n#variable that stores the Discrete Cosine Transform of each matrix\nDCTMat = np.zeros((len(Index),28,28))\nDCTMat2 = np.zeros((len(Index),28,28))\n\n# For the amount of elements established\nfor i in range(len(Index)):\n    # computing the Two-dimensional DCT in each matrix \n    DCTMat[i] = fft.dctn(ReshapedPanda[Index[i]-1],norm=\"ortho\")\n\n# Example to plot\nfor j in range(len(Index2)):\n    # computing the Two-dimensional DCT in each matrix \n    DCTMat2[j] = fft.dctn(ReshapedPanda[Index2[j]-1],norm=\"ortho\")\n\n    # Plotting the resultant DCT\n    plt.subplot(2, 5, j+1)\n    plt.title(f\"{Index2[j]}\")\n    plt.imshow(DCTMat2[j], 'gray')\n        \nplt.suptitle(\"(a) 2D Discrete Cosine Transform\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***\n**(b) (10 points) Extract the vertical, horizontal and diagonal coefficients from the transform.**\n***","metadata":{}},{"cell_type":"code","source":"# Diagonal mask matrix\ndiagonalMask = np.array([[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n            [0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n            [0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n            [0,0,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n            [0,0,0,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n            [0,0,0,0,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n            [0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n            [0,0,0,0,0,0,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n            [0,0,0,0,0,0,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n            [0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0],\n            [0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0],\n            [0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0],\n            [0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0],\n            [0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],\n            [0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],\n            [0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],\n            [0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],\n            [0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],\n            [0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],\n            [0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],\n            [0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],\n            [0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],\n            [0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],\n            [0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],\n            [0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],\n            [0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],\n            [0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],\n            [0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]])\n\nverticalMask = np.array([[0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],\n            [0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],\n            [0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],\n            [0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],\n            [0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],\n            [0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],\n            [0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],\n            [0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],\n            [0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],\n            [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1],\n            [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1],\n            [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1],\n            [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1],\n            [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n            [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n            [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n            [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n            [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n            [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n            [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n            [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n            [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n            [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n            [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n            [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n            [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n            [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n            [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]])\n\nhorizontalMask = np.array([[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n            [1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n            [1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n            [1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n            [1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n            [1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n            [1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n            [1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n            [1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n            [1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n            [1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n            [1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n            [1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n            [1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n            [1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n            [1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n            [1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n            [1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n            [1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n            [1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n            [1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n            [1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n            [1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n            [1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n            [1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n            [1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n            [1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n            [1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]])\n\nplt.subplot(1, 3, 1)\nplt.imshow(verticalMask, 'gray')\nplt.title(\"Vertical mask\")\nplt.subplot(1, 3, 2)\nplt.imshow(horizontalMask, 'gray')\nplt.title(\"Horizontal mask\")\nplt.subplot(1, 3, 3)\nplt.imshow(diagonalMask, 'gray')\nplt.title(\"Diagonal mask\")\n\nplt.suptitle(\"(b) Representation of masks\")\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Diagonal Coefficients","metadata":{}},{"cell_type":"code","source":"#variable that stores the diagonal coefficients matrix\ndiagonalCoefficients = np.zeros((len(Index),28,28))\n\n# initializing vector for the concatenation of coefficients\ndiagonalVector = []\n\nfor i in range(len(Index)):\n  diagonalCoefficients[i] = np.multiply(DCTMat[i],diagonalMask)\n  if plotControl == 1:\n    plt.subplot(2, 5, i+1)\n    plt.title(f\"{Index[i]}\")\n    plt.imshow(diagonalCoefficients[i],\"gray\")\n\n  for row in range(28):\n    for col in range(28):\n      if diagonalCoefficients[i][row][col] != 0:\n        diagonalVector.append(diagonalCoefficients[i][row][col])\n\nif plotControl == 1:\n  plt.suptitle(\"Diagonal Coefficients\")\n\n#number of coefficients\namountofCoef = int(len(diagonalVector)/len(Index))\ndiagonalVector = np.array(diagonalVector)\n\n# The diagonal coefficient vector is reshaped\ncoefDiagonal = diagonalVector.reshape(len(Index),amountofCoef)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Horizontal Coefficients","metadata":{}},{"cell_type":"code","source":"#variable that stores the diagonal coefficients matrix\nhorizontalCoefficients = np.zeros((len(Index),28,28))\n\n# initializing vector for the concatenation of coefficients\nhorizontalVector = []\n\nfor i in range(len(Index)):\n  horizontalCoefficients[i] = np.multiply(DCTMat[i],horizontalMask)\n  if plotControl == 1:\n    plt.subplot(2, 5, i+1)\n    plt.title(f\"{Index[i]}\")\n    plt.imshow(horizontalCoefficients[i],\"gray\")\n\n  for row in range(28):\n    for col in range(28):\n      if horizontalCoefficients[i][row][col] != 0:\n        horizontalVector.append(horizontalCoefficients[i][row][col])\nif plotControl == 1:\n  plt.suptitle(\"Horizontal Coefficients\")\n\n#number of coefficients\namountofCoef = int(len(horizontalVector)/len(Index))\nhorizontalVector = np.array(horizontalVector)\n\n# The diagonal coefficient vector is reshaped\ncoefHorizontal = horizontalVector.reshape(len(Index),amountofCoef)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Vertical Coefficients","metadata":{}},{"cell_type":"code","source":"#variable that stores the diagonal coefficients matrix\nverticalCoefficients = np.zeros((len(Index),28,28))\n\n# initializing vector for the concatenation of coefficients\nverticalVector = []\n\nfor i in range(len(Index)):\n  verticalCoefficients[i] = np.multiply(DCTMat[i],verticalMask)\n  if plotControl == 1:\n    plt.subplot(2, 5, i+1)\n    plt.title(f\"{Index[i]}\")\n    plt.imshow(verticalCoefficients[i],\"gray\")\n\n  for row in range(28):\n    for col in range(28):\n      if verticalCoefficients[i][row][col] != 0:\n        verticalVector.append(verticalCoefficients[i][row][col])\n\nif plotControl == 1:\n  plt.suptitle(\"Vertical Coefficients\")\n\n#number of coefficients\namountofCoef = int(len(verticalVector)/len(Index))\nverticalVector = np.array(verticalVector)\n\n# The diagonal coefficient vector is reshaped\ncoefVertical = verticalVector.reshape(len(Index),amountofCoef)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***\n**(c) (10 points) For each of the three sets of DCT coefficients perform Principal Component Analysis (PCA).**\n***","metadata":{}},{"cell_type":"code","source":"# the PCA is computed for each of the coefficients array\ndiagonalPCA = PCA().fit(coefDiagonal)\nverticalPCA = PCA().fit(coefVertical)\nhorizontalPCA = PCA().fit(coefHorizontal)\n\n# After fitting the data to PCA, the parameters are obtained\ndiagonalParameters = PCA(diagonalPCA).get_params\nverticalParameters = PCA(verticalPCA).get_params\nhorizontalParameters = PCA(horizontalPCA).get_params","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***\n**(d) (10 Points) Retain either the top n number of principal components or the top principal components with maximum variance.**\n***","metadata":{}},{"cell_type":"code","source":"# getting eigen vectors\ndiagonalEigenVectors = diagonalPCA.components_\nhorizontalEigenVectors = horizontalPCA.components_\nverticalEigenVectors = verticalPCA.components_\n\n#gettin the eigen values\ndiagonalEigenValues = diagonalPCA.explained_variance_\nhorizontalEigenValues = horizontalPCA.explained_variance_\nverticalEigenValues = verticalPCA.explained_variance_\n\nC_explained = diagonalPCA.explained_variance_ratio_","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*Plotting the first 50 values*","metadata":{}},{"cell_type":"code","source":"C_explained2 = C_explained[0:50]\nplt.figure()\n\nplt.scatter(np.arange(1,C_explained2.size+1),np.cumsum(C_explained2)*100,color=\"Red\")\nplt.axhline(y=90, color='g', linestyle='--')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*Plotting the second 50 values*","metadata":{}},{"cell_type":"code","source":"C_explained2 = C_explained[50:100]\n\nplt.figure()\n\nplt.scatter(np.arange(1,C_explained2.size+1),np.cumsum(C_explained2)*100,color=\"Red\")\nplt.axhline(y=5, color='green', linestyle='--')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As demonstrated above, in the first graph by using the first 50 components, more than 90% is obtained as seen with the green line. In the second graph, the second 50 components are plotted and this gives an increase of approximately between 5% and 6% as demonstrated with the green line, so only the top 50 components are used. \nSo n = 50.","metadata":{}},{"cell_type":"markdown","source":"***\n**(e) (10 points) Using your top principal components reduce the DCT transformed data. This will create a new data set that represents.**\n***","metadata":{}},{"cell_type":"code","source":"### Taking the top 50 eigen vectors\nn = 50\n# Diagonal components\ndiagonalEigenVectors[0:n,:].shape\nnp.matmul(coefDiagonal,diagonalEigenVectors[0:n:].T).shape\npcaFeaturesDiagonal = np.matmul(coefDiagonal,diagonalEigenVectors[0:n,:].T)\n\n# Horizontal components\nhorizontalEigenVectors[0:n,:].shape\nnp.matmul(coefHorizontal,horizontalEigenVectors[0:n:].T).shape\npcaFeaturesHorizontal = np.matmul(coefHorizontal,horizontalEigenVectors[0:n,:].T)\n\n# Vertical components\nverticalEigenVectors[0:n,:].shape\nnp.matmul(coefVertical,verticalEigenVectors[0:n:].T).shape\npcaFeaturesVertical = np.matmul(coefVertical,verticalEigenVectors[0:n,:].T)\n\n# label row is inserted in the output data\nlabelHeaderRow = np.array(TrainPanda.iloc[0:n,0])\npcaFeaturesVertical = np.insert(pcaFeaturesVertical, 0, labelHeaderRow, 0)\npcaFeaturesDiagonal = np.insert(pcaFeaturesDiagonal, 0, labelHeaderRow, 0)\npcaFeaturesHorizontal = np.insert(pcaFeaturesHorizontal, 0, labelHeaderRow, 0)\n\n# All the features are stacked on preparation for the output\npcaFeaturesTotal = np.hstack((pcaFeaturesDiagonal,pcaFeaturesVertical))\npcaFeaturesTotal = np.hstack((pcaFeaturesTotal,pcaFeaturesHorizontal))\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***\n**(5 points) Save the new data in a file of your choice, .txt, .csv, etc.**\n***","metadata":{}},{"cell_type":"code","source":"# Saving the new data into a csv fle\n\n#name of the file\noutPutFileName = \"RAlvarezHW2.csv\"\n\n# opening the file / creating the file to write\noutputFile = open(outPutFileName, 'w')\nwriter = csv.writer(outputFile)\n\n# looping over the resultant features\nfor i in range (len(pcaFeaturesTotal)):\n    writer.writerow(pcaFeaturesTotal[i])\n#closing the file\noutputFile.close()","metadata":{},"execution_count":null,"outputs":[]}]}